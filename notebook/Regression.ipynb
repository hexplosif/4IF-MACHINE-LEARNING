{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install numpy\n",
    "#! pip install pandas\n",
    "#! pip install scikit-learn\n",
    "#! pip install xgboost\n",
    "#! pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, HalvingRandomSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, VotingRegressor, StackingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.utils import resample\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/regression/train.csv\")\n",
    "\n",
    "test_df = pd.read_csv(\"../data/regression/test.csv\")\n",
    "\n",
    "sample_submission = pd.read_csv(\"../data/regression/sample_submission.csv\")\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ajout d'un indicateur pour différencier train/test et traitement de 'co2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"is_train\"] = 1\n",
    "test_df[\"is_train\"] = 0\n",
    "test_df[\"co2\"] = np.nan\n",
    "data = pd.concat([train_df, test_df], sort=False)\n",
    "data_index = data[\"id\"]\n",
    "data = data.drop(\"id\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Traitement de la variable 'hc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['hc'] = data['hc'].fillna(data['hcnox'] - data['nox'])\n",
    "data = data.drop(columns=['hcnox'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imputation : pour les numériques et les catégoriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = data.select_dtypes(include=[\"float64\", \"int64\"]).columns.tolist()\n",
    "categorical_cols = data.select_dtypes(exclude=[\"float64\", \"int64\"]).columns.tolist()\n",
    "\n",
    "for col in numeric_cols:\n",
    "    data[col] = data[col].fillna(data[col].median())\n",
    "for col in categorical_cols:\n",
    "    data[col] = data[col].fillna(\"missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encodage one-hot pour les variables catégoriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Séparation train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[data[\"is_train\"] == 1].drop(\"is_train\", axis=1)\n",
    "test_data = data[data[\"is_train\"] == 0].drop([\"is_train\", \"co2\"], axis=1)\n",
    "y_train = train_data[\"co2\"]\n",
    "X_train = train_data.drop(\"co2\", axis=1)\n",
    "\n",
    "print(\"Processed X_train shape:\", X_train.shape)\n",
    "print(\"Processed test_data shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pour accélérer le tuning, on effectue d'abord une recherche sur un sous-échantillon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample, y_train_sample = resample(X_train, y_train, n_samples=15000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Définition d’un pipeline simple (ici les données sont déjà numériques après get_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", ExtraTreesRegressor(random_state=42, n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Définition de la grille de recherche pour ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"model__n_estimators\": np.arange(300, 500, 20).tolist(),\n",
    "    \"model__max_depth\": [30, 35, 40, 45, 50, 55, 60, 65, 70],\n",
    "    \"model__min_samples_split\": [2, 3, 4, 5],\n",
    "    \"model__min_samples_leaf\": [1, 2, 3, 4, 5],\n",
    "    \"model__max_features\": [\"sqrt\", \"log2\", 0.5, 0.75, 0.9, 0.95, 0.99, None],\n",
    "    \"model__bootstrap\": [True, False],\n",
    "    \"model__criterion\": [\"squared_error\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Utiliser HalvingRandomSearchCV pour une recherche rapide et efficace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HalvingRandomSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_grid,\n",
    "    factor=3,  # Diminue rapidement le nombre de candidats moins prometteurs\n",
    "    scoring=\"neg_mean_absolute_error\",  # Puisque l'objectif est de minimiser le MAE\n",
    "    n_jobs=-1,\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    max_resources=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mesurer le temps d'exécution du tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "tuner.fit(X_train_sample, y_train_sample)\n",
    "tuning_time = time.time() - start_time\n",
    "print(f\"Temps de tuning sur l'échantillon: {tuning_time:.2f} secondes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Afficher les meilleurs hyperparamètres trouvés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Meilleurs paramètres trouvés :\", tuner.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extraction des paramètres pour ExtraTreesRegressor (en retirant le préfixe \"model__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_params = {key.replace(\"model__\", \"\"): value \n",
    "                     for key, value in tuner.best_params_.items() \n",
    "                     if key.startswith(\"model__\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Entraîner le meilleur modèle sur l'ensemble complet d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = ExtraTreesRegressor(n_estimators=9, random_state=17, n_jobs=-1)\n",
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prédictions sur le test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = final_model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convertir les prédictions en entiers (si nécessaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"id\": test_df[\"id\"], \"co2\": test_preds.astype(int)})\n",
    "submission.to_csv(\"../result/regression/Final_ensemble_submission.csv\", index=False)\n",
    "print(\"Submission saved as Final_ensemble_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparer les données en ensembles d'entraînement et de test\n",
    "train_data = data[data[\"is_train\"] == 1].drop(\"is_train\", axis=1)\n",
    "test_data = data[data[\"is_train\"] == 0].drop([\"is_train\", \"co2\"], axis=1)\n",
    "\n",
    "# Séparer les ensembles d'entraînement en features et target\n",
    "y_train = train_data[\"co2\"]\n",
    "X_train = train_data.drop(\"co2\", axis=1)\n",
    "\n",
    "print(\"Processed X_train shape:\", X_train.shape)\n",
    "print(\"Processed test_data shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TRAINING AND PREDICTION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Which model would you like to use?\")\n",
    "print(\"1. RandomForestRegressor\")\n",
    "print(\"2. GradientBoostingRegressor\")\n",
    "print(\"3. AdaBoostRegressor\")\n",
    "print(\"4. ExtraTreesRegressor\")\n",
    "print(\"5. BaggingRegressor\")\n",
    "print(\"6. VotingRegressor\")\n",
    "print(\"7. StackingRegressor\")\n",
    "print(\"8. XGBRegressor\")\n",
    "\n",
    "model = 0\n",
    "\n",
    "while model == 0:\n",
    "\n",
    "    model_choice = input(\": \")\n",
    "\n",
    "    match model_choice:\n",
    "        case \"1\":\n",
    "            model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "        case \"2\":\n",
    "            model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "        case \"3\":\n",
    "            model = AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "        case \"4\":\n",
    "            model = ExtraTreesRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "        case \"5\":\n",
    "            model = BaggingRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "        case \"6\":\n",
    "            model = VotingRegressor(estimators=[(\"rf\", RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)),\n",
    "                                                (\"gb\", GradientBoostingRegressor(n_estimators=100, random_state=42))],\n",
    "                                    n_jobs=-1)\n",
    "        case \"7\":\n",
    "            model = StackingRegressor(estimators=[(\"rf\", RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)),\n",
    "                                                  (\"gb\", GradientBoostingRegressor(n_estimators=100, random_state=42))],\n",
    "                                      final_estimator=RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "                                      n_jobs=-1)\n",
    "        case \"8\":\n",
    "            model = XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "        case _:\n",
    "            model = 0\n",
    "            print(\"Invalid choice.\")\n",
    "\n",
    "print(\"Model chosen:\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### QUICK TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réduire la taille des données pour les tests rapides\n",
    "X_train_sample, y_train_sample = resample(X_train, y_train, n_samples=5000, random_state=42)\n",
    "\n",
    "# Test rapide sur un sous-échantillon\n",
    "model.fit(X_train_sample, y_train_sample)\n",
    "y_pred_sample = model.predict(X_train_sample)\n",
    "mae_sample = mean_absolute_error(y_train_sample, y_pred_sample)\n",
    "\n",
    "print(\"Quick test MAE on sample data: {:.4f}\".format(mae_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results :\n",
    "\n",
    "Random Forest Regressor :\n",
    "- Cross Validation MAE: 0.14\n",
    "- Time required for training: 1s\n",
    "\n",
    "Gradient Boosting Regressor :\n",
    "- Cross Validation MAE: 0.6887\n",
    "- Time required for training: 6s\n",
    "\n",
    "AdaBoost Regressor :\n",
    "- Cross Validation MAE: 5.11\n",
    "- Time required for training: 1m 11s\n",
    "\n",
    "Extra Trees Regressor :\n",
    "- Cross Validation MAE: 0.008 (old test, long but accurate) 0.0024 (new test, fast but less accurate)\n",
    "- Time required for training: 10min 11s (old test, long but accurate) 1s (new test, fast but less accurate)\n",
    "\n",
    "Bagging Regressor :\n",
    "- Cross Validation MAE: 0.1392\n",
    "- Time required for training: 45.6s\n",
    "\n",
    "Voting Regressor :\n",
    "- Cross Validation MAE: 0.4\n",
    "- Time required for training: 8s\n",
    "\n",
    "Stacking Regressor :\n",
    "- Cross Validation MAE: 0.13\n",
    "- Time required for training: 25m\n",
    "\n",
    "XGBoost Regressor :\n",
    "- Cross Validation MAE: 0.19\n",
    "- Time required for training: 2s\n",
    "\n",
    "LightGBM Regressor :\n",
    "- Cross Validation MAE: 0.19\n",
    "- Time required for training: 1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "\n",
    "est_preds = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SUBMISSION FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construire le fichier de soumission, le format requis est: id,co2\n",
    "\n",
    "print(f\"Taille de sample_submission: {sample_submission.shape}\")\n",
    "print(f\"Taille de test_preds: {test_preds.shape}\")\n",
    "\n",
    "submission = pd.DataFrame(\n",
    "    {\n",
    "        \"id\": sample_submission[\"id\"],\n",
    "        \"co2\": test_preds.astype(int),  # les valeurs doivent être des entiers\n",
    "    }\n",
    ")\n",
    "\n",
    "model_name = str(model).split(\"(\")[0]\n",
    "submission.to_csv(f\"../result/regression/{model_name}_submission.csv\", index=False)\n",
    "print(f\"Submission saved as {model_name}_submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
