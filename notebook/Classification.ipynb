{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Electricity pricing is a critical aspect of energy markets, influencing both consumers and suppliers. In this project, we analyze electricity price trends in **British Columbia (BC)** and **Alberta (AB)**, Canada, using historical electricity measurements. Our objective is to develop a predictive model that estimates whether the electricity price in British Columbia will **increase (UP)** or **decrease (DOWN)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "Given a dataset containing electricity-related metrics, we aim to predict the **bc_price_evo** variable, which indicates whether the electricity price in BC is increasing or decreasing. The dataset includes:\n",
    "\n",
    "- **Date and Time of measurement**\n",
    "- **Electricity Price and Demand** in British Columbia and Alberta\n",
    "- **Electricity Transfer** between the two regions\n",
    "\n",
    "The ultimate goal is to build an accurate machine learning model that can effectively classify price movement in BC.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metric\n",
    "\n",
    "Our model will be evaluated using the **Accuracy Score**, which measures the percentage of correct predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```math\n",
    "\\text{Accuracy} = \\frac{\\text{Number of correct predictions}}{\\text{Total predictions}}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A higher accuracy score indicates a better-performing model.\n",
    "\n",
    "### Submission Format\n",
    "\n",
    "The submission should be a CSV file containing the predicted **bc_price_evo** values for each test ID. The format should be:\n",
    "\n",
    "```csv\n",
    "id,bc_price_evo \n",
    "28855,UP \n",
    "28856,UP \n",
    "28857,DOWN ...\n",
    "```\n",
    "\n",
    "\n",
    "This project will explore various machine learning techniques to improve prediction accuracy and gain insights into electricity price fluctuations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "\n",
    "For this project, we will use some libraries that can help us facilitate the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                 # pandas for the data structure manipulation \n",
    "import numpy as np                  # numpy for numerical operations\n",
    "import matplotlib.pyplot as plt     # matplotlib for plotting\n",
    "#import sklearn as sklearn          # sklearn for machine learning and evaluation (required module will be imported later in each partie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document outlines a step-by-step approach to handling data using Python. The process includes data loading, inspecting, handling missing values, and data normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/classification/'\n",
    "output_dir = '../output/classification/submission/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading Data  \n",
    "The first step is to import the necessary libraries and load the dataset into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_raw = pd.read_csv(data_dir + 'train.csv', index_col=0)\n",
    "df_train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_raw = pd.read_csv(data_dir + 'test.csv', index_col=0)\n",
    "df_test_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Inspection  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the trainning and testing dataset, we will see that there are 7 columns, which will provide information for the predictions. Those are:\n",
    "- `id` - Unique identifier used by Kaggle\n",
    "\n",
    "- `date` - Date at which the measurement was made, between the 15th of May 2015 and the 13th of December 2017 (normalized between 0 and 1)\n",
    "- `hour` - Hour of measurement as a half hour period of time over 24 hours (values originally between 0 and 47, here normalized between 0 and 1)\n",
    "- `bc_price` - Electricity price in British Columbia (normalized between 0 and 1)\n",
    "- `bc_demand` - Electricity demand in British Columbia (normalized between 0 and 1)\n",
    "- `ab_price` - Electricity price in Alberta (normalized between 0 and 1)\n",
    "- `ab_demand` - Electricity demand in Alberta (normalized between 0 and 1)\n",
    "- `transfer` - Electricity transfer scheduled between British Columbia and Alberta (normalized between 0 and 1)\n",
    "- `bc_price_evo` - Is the price in British Columbia going UP or DOWN compared to the last 24 hours? This is the target variable (i.e., it is only given during training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before processin,  it's essential to check the structure and properties of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_raw.info()\n",
    "df_train_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_raw.info()\n",
    "df_train_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent, it seems that our data is really clean, there is no missing values and complex information are already normalized. So it could be ready for the processing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data preparing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the training process, we will need to seperate the data and the predictions (the labels in the `bc_price_evo` column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_raw.drop(columns=['bc_price_evo'])\n",
    "df_train_labels = df_train_raw.loc[:, 'bc_price_evo'].copy()\n",
    "\n",
    "df_train.head()\n",
    "df_train_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the testing dataset, it's already okay, and we can use the raw data for the prediction. But we want to make things more concurrent, so we will define the save submission function, which will save our predictions in a csv file for the submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission( df_test_labels, name_model  ):\n",
    "    test = df_test.copy()\n",
    "    test['bc_price_evo'] = df_test_labels\n",
    "    test.to_csv(f'../data/classification/submission/{name_model}.csv', columns=['bc_price_evo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is a statistical method used for binary classification tasks. Unlike linear regression, which predicts continuous values, logistic regression predicts the probability that a given input belongs to a particular class. It applies the **sigmoid function** to transform linear predictions into probability values ranging from 0 to 1.  \n",
    "\n",
    "**How It Works**:\n",
    "1. Computes a weighted sum of input features.\n",
    "2. Applies the **sigmoid function** to map the result to a probability.\n",
    "3. Uses a decision threshold (typically 0.5) to classify data points into one of two categories.\n",
    "\n",
    "Logistic Regression is fully integrated by Scikit Learn library in the module linear_model package, and we can use it as our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression of ScikitLearn supported a lot of hyperparameters, like `max_iter`, `C` (Inverse of regularization strength), `random_state`, ... And chosing the right hyperparameters for the model is really complicated. To solve this, we decide to do the eastimation of accuracy: we will seperate the training dataset into sub_training dataset and sub_validation dataset, we will use this for the training and validation of our model, and get the accuracy (of course, this is not the actual accuracy, it is only the estimate of the accuracy which will help us somehow decide the better hyperparameters. )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train, df_train_labels, test_size=0.20, random_state=23)\n",
    "clf = LogisticRegression(max_iter=10000, random_state=0, C=15, class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "acc = accuracy_score(y_test, clf.predict(X_test)) * 100\n",
    "print(f\"Logistic Regression model accuracy: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preceding scripts show how we estimate the accuracy of the model with the hyparameters `max_iter=10000, random_state=0, C=15, class_weight='balanced'`. Doing this with another case, we will have the estimated accuracy tables\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Solver (d=lbfgs) | C (d=1.0) | Penalty (d=l2) | Class Weight (d=None) | Fit Intercept (d=True) | L1 Ratio (d=None) | Accuracy (%) |\n",
    "|--------|----|---------|--------------|--------------|----------|--------------|\n",
    "| default | default | default | default | default | default | 74.01 |\n",
    "| liblinear | default | default | default | default | default | 73.94 |\n",
    "| default | 0.01 | default | default | default | default | 62.97 |\n",
    "| default | 0.1  | default | default | default | default | 66.77 |\n",
    "| default | 10   | default | default | default | default | 75.05 |\n",
    "| default | 100  | default | default | default | default | 74.96 |\n",
    "| default | 15   | default | default | default | default | 75.12 |\n",
    "| liblinear | 15 | l1 | default | default | default | 75.00 |\n",
    "| saga | 15 | elasticnet | default | default | 0.5 | 75.08 |\n",
    "| default | 15 | default | balanced | default | default | 75.13 |\n",
    "| default | 15 | default | balanced | False | default | 71.65 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the table below, the highest estimated accuracy is `max_iter=10000, random_state=0, C=15, class_weight='balanced'` with accuracy = 75.12%. So we can use this for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=10000, random_state=0, C=15, class_weight='balanced')\n",
    "clf.fit(df_train, df_train_labels)\n",
    "test_labels = clf.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat test_labels to df_test index\n",
    "save_submission(test_labels, 'LogisticRegression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our predictions is saved in csv file, and we now can send it to Kaggle for the submission. The result is 0.7284, not too high but still a good value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train, df_train_labels, test_size=0.3, random_state=21)\n",
    "dtree = DecisionTreeClassifier(random_state=1, max_depth=20)\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "acc = accuracy_score(y_test, dtree.predict(X_test)) * 100\n",
    "print(f\"Decision Tree model accuracy: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Criterion (d=gini) | Max Depth (d=None) | Min Samples Split (d=2) | Min Samples Leaf (d=1) | Accuracy (%) |\n",
    "|---------|---------|--------------|--------------|--------------|\n",
    "| default | default | default | default | 84.63 |\n",
    "| default | default | 5 | default | 84.61 |\n",
    "| default | default | 10 | default | 84.27 |\n",
    "| default | default | 20 | 5 | 84.09 |\n",
    "| default | 20 | default | default | 85.06 |\n",
    "| default | 20 | 5 | default | 84.67 |\n",
    "| default | 20 | 10 | 5 | 84.38 |\n",
    "| default | 20 | 20 | 5 | 84.15 |\n",
    "| entropy | default | default | default | 84.73 |\n",
    "| entropy | default | 5 | default | 84.60 |\n",
    "| entropy | default | 10 | 5 | 84.13 |\n",
    "| entropy | 20 | default | default | 84.64 |\n",
    "| entropy | 20 | 5 | default | 84.45 |\n",
    "| entropy | 20 | 10 | 5 | 84.05 |\n",
    "| log_loss | default | default | default | 84.73 |\n",
    "| log_loss | default | 5 | default | 84.60 |\n",
    "| log_loss | default | 10 | 5 | 84.13 |\n",
    "| log_loss | 20 | default | default | 84.64 |\n",
    "| log_loss | 20 | 5 | default | 84.45 |\n",
    "| log_loss | 20 | 10 | 5 | 84.05 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best hyperparameters we get according to the table is: `criterion=\"gini\", max_depth=20, min_samples_split=2, min_samples_leaf=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(random_state=1, max_depth=20)\n",
    "dtree.fit(df_train, df_train_labels)\n",
    "dtree_test_labels = dtree.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_submission(dtree_test_labels, 'DecisionTree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree model's predictions are saved in csv file, the result on Kaggle is 0.8648."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df_train, df_train_labels, test_size=0.2, random_state=28)\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "acc = accuracy_score(y_test, rf_model.predict(X_test)) * 100\n",
    "print(f\"Decision Tree model accuracy: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| N Estimators (d=100) | Max Depth (d=None) | Min Samples Split (d=2) | Min Samples Leaf (d=1) | Accuracy (%) |\n",
    "|---------|---------|--------------|--------------|--------------|\n",
    "| 50 | default | default | default | 97.46 |\n",
    "| 50 | default | default | 5 | 91.53 |\n",
    "| 50 | default | 5 | default | 96.85 |\n",
    "| 50 | default | 5 | 5 | 91.53 |\n",
    "| 50 | default | 10 | default | 94.63 |\n",
    "| 50 | default | 10 | 5 | 91.53 |\n",
    "| 50 | default | 20 | default | 91.37 |\n",
    "| 50 | 20 | default | default | 97.15 |\n",
    "| 50 | 20 | default | 5 | 91.32 |\n",
    "| 50 | 20 | 5 | default | 96.53 |\n",
    "| 50 | 20 | 5 | 5 | 91.32 |\n",
    "| 50 | 20 | 10 | default | 94.31 |\n",
    "| 50 | 20 | 10 | 5 | 91.32 |\n",
    "| 50 | 20 | 20 | default | 91.02 |\n",
    "| default | default | default | default | 97.47 |\n",
    "| default | default | default | 5 | 91.67 |\n",
    "| default | default | 5 | default | 96.95 |\n",
    "| default | default | 5 | 5 | 91.67 |\n",
    "| default | default | 10 | default | 94.98 |\n",
    "| default | default | 10 | 5 | 91.67 |\n",
    "| default | default | 20 | default | 91.63 |\n",
    "| default | 20 | default | default | 97.35 |\n",
    "| default | 20 | default | 5 | 91.64 |\n",
    "| default | 20 | 5 | default | 96.66 |\n",
    "| default | 20 | 5 | 5 | 91.64 |\n",
    "| default | 20 | 10 | default | 94.49 |\n",
    "| default | 20 | 10 | 5 | 91.64 |\n",
    "| default | 20 | 20 | default | 90.97 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best hyperparameters we get according to the table are the default parameters, which has the accuracy of 97.47%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(random_state=1)\n",
    "rf_model.fit(df_train, df_train_labels)\n",
    "rf_test_labels = rf_model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_submission(rf_test_labels, 'RandomForest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest model's predictions are saved in csv file, the result on Kaggle is 0.8816."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Support Vector Machine (SVM)\n",
    "\n",
    "Support Vector Machine (SVM) is a powerful supervised learning algorithm used for classification and regression tasks.  \n",
    "It works by finding the optimal hyperplane that best separates data points into different classes.  \n",
    "\n",
    "Key concepts of SVM include:  \n",
    "- **Margin Maximization**: SVM aims to maximize the margin between the closest data points (support vectors) and the decision boundary.  \n",
    "- **Kernel Trick**: SVM can handle non-linearly separable data by using kernel functions (e.g., linear, polynomial, RBF) to map data into a higher-dimensional space.  \n",
    "- **Regularization (C Parameter)**: Controls the trade-off between achieving a low error rate and maintaining a large margin.  \n",
    "\n",
    "SVM is fully integrated by Scikit Learn library in the module svm package with the class SVC, and we can use it as our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from matplotlib.pylab import RandomState"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the process of estimation accuracy we have used in LogisticRegression, we will do the same thing to choose the hyperparameters we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train, df_train_labels, test_size=0.20, random_state=RandomState())\n",
    "svm = SVC(kernel=\"rbf\", gamma=20, C=100.0, class_weight='balanced', max_iter=100000)\n",
    "svm.fit(X_train, y_train)\n",
    "acc = accuracy_score(y_test, svm.predict(X_test)) * 100\n",
    "print(f\"Logistic Regression model accuracy: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the estimated accuracy tables we get is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Kernel (d='rbf') | Gamma (d='scale') | C (d=1.0)     | Degree (d=3) | Coef0 (d=0.0) | Class Weight (d=None) | Max Iter (d=-1) | Accuracy (%) |\n",
    "|---------|--------|--------|--------|-------|--------------|-----------|--------------|\n",
    "| rbf     | 0.5    | 1.0    | default | default | default | default | 76.33 |\n",
    "| rbf     | 0.5    | 10.0   | default | default | default | default | 77.39 |\n",
    "| rbf     | 0.5    | 100.0  | default | default | default | default | 78.39 |\n",
    "| rbf     | default| 100.0  | default | default | default | default | 79.83 |\n",
    "| linear  | default| 100.0  | default | default | default | default | 74.75 |\n",
    "| sigmoid | default| 100.0  | default | default | default | default | 43.20 |\n",
    "| poly    | default| 100.0  | default | default | default | default | 76.42 |\n",
    "| rbf     | scale  | 100.0  | default | default | default | default | 79.83 |\n",
    "| rbf     | auto   | 100.0  | default | default | default | default | 76.78 |\n",
    "| rbf     | 0.01   | 100.0  | default | default | default | default | 75.60 |\n",
    "| rbf     | 0.1    | 100.0  | default | default | default | default | 76.76 |\n",
    "| rbf     | 1      | 100.0  | default | default | default | default | 78.66 |\n",
    "| rbf     | 5      | 100.0  | default | default | default | default | 80.70 |\n",
    "| rbf     | 10     | 100.0  | default | default | default | default | 81.37 |\n",
    "| rbf     | 20     | 100.0  | default | default | default | default | 82.05 |\n",
    "| rbf     | 20     | 100.0  | default | default | balanced | 100000    | 82.12 |\n",
    "| rbf     | 0.05   | 10.0   | 3      | default | default | default | 75.05 |\n",
    "| rbf     | 0.05   | 10.0   | 3      | 1      | balanced | 5000      | 75.05 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the best hyperparameters we get according to the table is: `kernel=\"rbf\", gamma=20, C=100.0, class_weight='balanced', max_iter=-1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel=\"rbf\", gamma=20, C=100.0, class_weight='balanced', max_iter=-1) #82.12%\n",
    "svm.fit(df_train, df_train_labels)\n",
    "test_labels = svm.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_submission(test_labels, 'SVM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our predictions is saved in csv file, and we now can send it to Kaggle for the submission. The result is 0.8176, not too high but still a good value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Naive Bayes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our features are continuous numerical values, the best choice is GaussianNB because:\n",
    "\n",
    "- It assumes features are normally distributed (which is common for numerical data).\n",
    "\n",
    "- Other Naïve Bayes variants (like MultinomialNB, ComplementNB, and BernoulliNB) are designed for discrete/categorical data and are not suitable for continuous numerical data.\n",
    "\n",
    "Attention : Naïve Bayes models in scikit-Learn require numerical labels instead of string labels (`'UP'` / `'DOWN'`). Therefore, we need to transform `'UP'` -> `1` and `'DOWN'` -> `0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UP → 1, DOWN → 0\n",
    "label_encoder = LabelEncoder()\n",
    "df_train_labels_encode = label_encoder.fit_transform(df_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train, df_train_labels_encode, test_size=0.3, random_state=21)\n",
    "\n",
    "gnb = GaussianNB(var_smoothing=1e-3)\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "acc = accuracy_score(y_test, gnb.predict(X_test)) * 100\n",
    "print(f\"Gaussian Naive Bayes model accuracy: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Var Smoothing (d=1e-9) | Accuracy (%) |\n",
    "|---------|---------|\n",
    "| default | 68.65 |\n",
    "| 1e-10 | 68.65 |\n",
    "| 1e-08 | 68.65 |\n",
    "| 1e-07 | 68.65 |\n",
    "| 1e-06 | 68.67 |\n",
    "| 1e-05 | 68.71 |\n",
    "| 0.0001 | 69.13 |\n",
    "| 0.001 | 70.00 |\n",
    "| 0.01 | 65.80 |\n",
    "| 0.1 | 62.42 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the best hyperparameter we get according to the table is: `var_smoothing=1e-3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB(var_smoothing=1e-3)\n",
    "gnb.fit(df_train, df_train_labels_encode)\n",
    "gnb_test_labels_encode = gnb.predict(df_test)\n",
    "\n",
    "gnb_test_labels = label_encoder.inverse_transform(gnb_test_labels_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_submission(gnb_test_labels, 'GaussianNB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes model's predictions are saved in csv file, the result on Kaggle is 0.6945, which is pretty low. However, it's normal for Naïve Bayes (NB) to perform worse than other models, e.g, Random Forest, kNN, or SVM for many reasons, for example:\n",
    "- Naïve Bayes assumes features are independent, which is rarely true in real-world data. \n",
    "- NB calculates probabilities independently for each feature, which can be inaccurate if features are correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UP → 1, DOWN → 0\n",
    "label_encoder = LabelEncoder()\n",
    "df_train_labels_encode = label_encoder.fit_transform(df_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df_train, df_train_labels_encode, test_size=0.2, random_state=28)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=9, weights=\"distance\", metric=\"manhattan\")\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "acc = accuracy_score(y_test, knn.predict(X_test)) * 100\n",
    "print(f\"kNN model accuracy: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| N Neighbors (d=5) | Weights (d='uniform') | Metric (d='minkowski') | Accuracy (%) |\n",
    "|---------|----------|-----------|--------------|\n",
    "| 1 | uniform | minkowski | 94.64 |\n",
    "| 1 | uniform | euclidean | 94.64 |\n",
    "| 1 | uniform | manhattan | 94.85 |\n",
    "| 1 | uniform | chebyshev | 94.50 |\n",
    "| 1 | distance | minkowski | 94.64 |\n",
    "| 1 | distance | euclidean | 94.64 |\n",
    "| 1 | distance | manhattan | 94.85 |\n",
    "| 1 | distance | chebyshev | 94.50 |\n",
    "| 3 | distance | minkowski | 95.23 |\n",
    "| 3 | distance | euclidean | 95.23 |\n",
    "| 3 | distance | manhattan | 95.43 |\n",
    "| 3 | distance | chebyshev | 95.07 |\n",
    "| 5 | distance | minkowski | 95.39 |\n",
    "| 5 | distance | euclidean | 95.39 |\n",
    "| 5 | distance | manhattan | 95.59 |\n",
    "| 5 | distance | chebyshev | 95.15 |\n",
    "| 7 | distance | minkowski | 95.59 |\n",
    "| 7 | distance | euclidean | 95.59 |\n",
    "| 7 | distance | manhattan | 95.68 |\n",
    "| 7 | distance | chebyshev | 95.29 |\n",
    "| 9 | distance | minkowski | 95.52 |\n",
    "| 9 | distance | euclidean | 95.52 |\n",
    "| 9 | distance | manhattan | 95.95 |\n",
    "| 9 | distance | chebyshev | 95.58 |\n",
    "| 11 | distance | minkowski | 95.53 |\n",
    "| 11 | distance | euclidean | 95.53 |\n",
    "| 11 | distance | manhattan | 95.84 |\n",
    "| 11 | distance | chebyshev | 95.75 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the best hyperparameter we get according to the table is: `n_neighbors=9, weights=\"distance\", metric=\"manhattan\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=9, weights=\"distance\", metric=\"manhattan\")\n",
    "knn.fit(df_train, df_train_labels_encode)\n",
    "knn_test_labels_encode = knn.predict(df_test)\n",
    "\n",
    "knn_test_labels = label_encoder.inverse_transform(knn_test_labels_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_submission(knn_test_labels, 'knn_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN model's predictions are saved in csv file, the result on Kaggle is 0.7870."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
