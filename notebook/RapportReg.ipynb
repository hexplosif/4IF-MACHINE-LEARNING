{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "regression-header",
   "metadata": {},
   "source": [
    "# Rapport du Défi de Régression\n",
    "\n",
    "**Membres du groupe :**\n",
    "- Adam Schlee\n",
    "- Truong Son Ngo\n",
    "- Jixiang Sun\n",
    "- Thi Tho Vu\n",
    "- Mohamed Fakroni\n",
    "- Mateo Carvajal Sanchez\n",
    "- Huu Thanh Tu Huynh\n",
    "- Santiago Forero Gutierrez\n",
    "\n",
    "Ce notebook présente l'approche utilisée pour relever le défi de régression. Il inclut le chargement et le prétraitement des données, la définition d’un pipeline et d’une grille d’hyperparamètres, le tuning avec HalvingRandomSearchCV, l’entraînement du modèle final, ainsi qu’un système interactif de sélection de modèles pour comparer différentes approches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regression-intro",
   "metadata": {},
   "source": [
    "## I. Introduction\n",
    "\n",
    "L'objectif de ce projet est de prédire la variable `co2` à partir d'un ensemble de variables explicatives. Plusieurs modèles de régression ont été testés et comparés (ExtraTreesRegressor, RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor, VotingRegressor, StackingRegressor, XGBRegressor, LightGBM). Le présent document détaille les étapes du prétraitement, la recherche d’hyperparamètres, le tuning du modèle et la génération du fichier de soumission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regression-imports",
   "metadata": {},
   "source": [
    "## II. Import des Bibliothèques et Chargement des Données\n",
    "\n",
    "Les bibliothèques nécessaires sont importées et les données de régression sont chargées depuis les fichiers CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install numpy\n",
    "#! pip install pandas\n",
    "#! pip install scikit-learn\n",
    "#! pip install xgboost\n",
    "#! pip install lightgbm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, HalvingRandomSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, VotingRegressor, StackingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.utils import resample\n",
    "import time\n",
    "\n",
    "##### Chargement des données\n",
    "train_df = pd.read_csv(\"../data/regression/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/regression/test.csv\")\n",
    "sample_submission = pd.read_csv(\"../data/regression/sample_submission.csv\")\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regression-preprocessing",
   "metadata": {},
   "source": [
    "## III. Prétraitement des Données\n",
    "\n",
    "Les données d'entraînement et de test sont concaténées pour appliquer un prétraitement commun :\n",
    "- Ajout d'un indicateur pour différencier les ensembles\n",
    "- Traitement spécifique de la variable `hc`\n",
    "- Imputation des valeurs manquantes pour les variables numériques et catégoriques\n",
    "- Encodage one-hot pour les variables catégoriques\n",
    "- Séparation finale en ensembles d'entraînement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-preprocessing",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Ajout d'un indicateur pour différencier train/test et traitement de 'co2'\n",
    "train_df[\"is_train\"] = 1\n",
    "test_df[\"is_train\"] = 0\n",
    "test_df[\"co2\"] = np.nan\n",
    "data = pd.concat([train_df, test_df], sort=False)\n",
    "data_index = data[\"id\"]\n",
    "data = data.drop(\"id\", axis=1)\n",
    "\n",
    "##### Traitement de la variable 'hc'\n",
    "data['hc'] = data['hc'].fillna(data['hcnox'] - data['nox'])\n",
    "data = data.drop(columns=['hcnox'])\n",
    "\n",
    "##### Imputation pour les variables numériques et catégoriques\n",
    "numeric_cols = data.select_dtypes(include=[\"float64\", \"int64\"]).columns.tolist()\n",
    "categorical_cols = data.select_dtypes(exclude=[\"float64\", \"int64\"]).columns.tolist()\n",
    "\n",
    "for col in numeric_cols:\n",
    "    data[col] = data[col].fillna(data[col].median())\n",
    "for col in categorical_cols:\n",
    "    data[col] = data[col].fillna(\"missing\")\n",
    "\n",
    "##### Encodage one-hot pour les variables catégoriques\n",
    "data = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "##### Séparation train/test\n",
    "train_data = data[data[\"is_train\"] == 1].drop(\"is_train\", axis=1)\n",
    "test_data = data[data[\"is_train\"] == 0].drop([\"is_train\", \"co2\"], axis=1)\n",
    "y_train = train_data[\"co2\"]\n",
    "X_train = train_data.drop(\"co2\", axis=1)\n",
    "\n",
    "print(\"Processed X_train shape:\", X_train.shape)\n",
    "print(\"Processed test_data shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regression-tuning",
   "metadata": {},
   "source": [
    "## IV. Recherche d'Hyperparamètres et Tuning\n",
    "\n",
    "Pour accélérer le tuning, nous sélectionnons d'abord un sous-échantillon (15 000 observations) de l’ensemble d'entraînement. Un pipeline simple, composé d'un `StandardScaler` et d'un `ExtraTreesRegressor`, est défini. Ensuite, une grille d'hyperparamètres est construite pour `ExtraTreesRegressor` et optimisée via `HalvingRandomSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Sous-échantillonnage pour le tuning\n",
    "X_train_sample, y_train_sample = resample(X_train, y_train, n_samples=15000, random_state=42)\n",
    "\n",
    "##### Définition du pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", ExtraTreesRegressor(random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "##### Définition de la grille d'hyperparamètres\n",
    "param_grid = {\n",
    "    \"model__n_estimators\": [7, 8, 9, 10, 11],\n",
    "    \"model__max_depth\": [None, 5, 10, 15, 20, 25, 30],\n",
    "    \"model__min_samples_split\": [2, 3, 4, 5],\n",
    "    \"model__min_samples_leaf\": [1, 2, 3, 4, 5],\n",
    "    \"model__max_features\": [\"sqrt\", \"log2\", None, 0.5, 0.75, 0.9],\n",
    "    \"model__bootstrap\": [True, False],\n",
    "    \"model__criterion\": [\"squared_error\"]\n",
    "}\n",
    "\n",
    "##### Optimisation avec HalvingRandomSearchCV\n",
    "tuner = HalvingRandomSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_grid,\n",
    "    factor=3,                              \n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    n_jobs=-1,\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    max_resources=\"auto\"\n",
    ")\n",
    "\n",
    "##### Mesure du temps de tuning\n",
    "start_time = time.time()\n",
    "tuner.fit(X_train_sample, y_train_sample)\n",
    "tuning_time = time.time() - start_time\n",
    "print(f\"Temps de tuning sur l'échantillon: {tuning_time:.2f} secondes\")\n",
    "\n",
    "##### Affichage des meilleurs hyperparamètres\n",
    "print(\"Meilleurs paramètres trouvés :\", tuner.best_params_)\n",
    "\n",
    "##### Extraction des paramètres (suppression du préfixe 'model__')\n",
    "best_model_params = {key.replace(\"model__\", \"\"): value \n",
    "                     for key, value in tuner.best_params_.items() \n",
    "                     if key.startswith(\"model__\")}\n",
    "print(\"Paramètres pour ExtraTreesRegressor :\", best_model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regression-final-model",
   "metadata": {},
   "source": [
    "## V. Entraînement du Modèle Final et Génération du Fichier de Soumission\n",
    "\n",
    "Une fois les hyperparamètres optimaux obtenus pour `ExtraTreesRegressor`, le modèle final est entraîné sur l’ensemble complet d'entraînement. Par ailleurs, un système interactif permet de sélectionner d'autres modèles (RandomForest, GradientBoosting, AdaBoost, etc.) pour des tests rapides avant de générer le fichier de soumission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-final-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Entraînement du modèle final avec ExtraTreesRegressor\n",
    "final_model = ExtraTreesRegressor(n_estimators=9, random_state=17, n_jobs=-1)   # Les meilleurs hyperparamètres trouvés\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "##### Prédictions sur l'ensemble de test\n",
    "test_preds = final_model.predict(test_data)\n",
    "\n",
    "##### Création du fichier de soumission (les prédictions sont converties en entiers)\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": test_df[\"id\"],\n",
    "    \"co2\": test_preds.astype(int)\n",
    "})\n",
    "submission.to_csv(\"../result/regression/Final_ensemble_submission.csv\", index=False)\n",
    "print(\"Submission saved as Final_ensemble_submission.csv\")\n",
    "\n",
    "##### Système interactif de sélection de modèle\n",
    "print(\"Which model would you like to use?\")\n",
    "print(\"1. RandomForestRegressor\")\n",
    "print(\"2. GradientBoostingRegressor\")\n",
    "print(\"3. AdaBoostRegressor\")\n",
    "print(\"4. ExtraTreesRegressor\")\n",
    "print(\"5. BaggingRegressor\")\n",
    "print(\"6. VotingRegressor\")\n",
    "print(\"7. StackingRegressor\")\n",
    "print(\"8. XGBRegressor\")\n",
    "\n",
    "model = 0\n",
    "\n",
    "while model == 0:\n",
    "    model_choice = input(\": \")\n",
    "    \n",
    "    match model_choice:\n",
    "        case \"1\":\n",
    "            from sklearn.ensemble import RandomForestRegressor\n",
    "            model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "        case \"2\":\n",
    "            from sklearn.ensemble import GradientBoostingRegressor\n",
    "            model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "        case \"3\":\n",
    "            from sklearn.ensemble import AdaBoostRegressor\n",
    "            model = AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "        case \"4\":\n",
    "            model = ExtraTreesRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "        case \"5\":\n",
    "            from sklearn.ensemble import BaggingRegressor\n",
    "            model = BaggingRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "        case \"6\":\n",
    "            from sklearn.ensemble import VotingRegressor\n",
    "            model = VotingRegressor(estimators=[\n",
    "                (\"rf\", RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)),\n",
    "                (\"gb\", GradientBoostingRegressor(n_estimators=100, random_state=42))\n",
    "            ], n_jobs=-1)\n",
    "        case \"7\":\n",
    "            from sklearn.ensemble import StackingRegressor\n",
    "            model = StackingRegressor(estimators=[\n",
    "                (\"rf\", RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)),\n",
    "                (\"gb\", GradientBoostingRegressor(n_estimators=100, random_state=42))\n",
    "            ], final_estimator=RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1), n_jobs=-1)\n",
    "        case \"8\":\n",
    "            model = XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "        case _:\n",
    "            print(\"Invalid choice. Please select a valid model.\")\n",
    "            model = 0\n",
    "\n",
    "print(\"Model chosen:\", model)\n",
    "\n",
    "##### Test rapide sur un sous-échantillon pour vérifier le modèle choisi\n",
    "X_train_sample, y_train_sample = resample(X_train, y_train, n_samples=5000, random_state=42)\n",
    "model.fit(X_train_sample, y_train_sample)\n",
    "y_pred_sample = model.predict(X_train_sample)\n",
    "mae_sample = mean_absolute_error(y_train_sample, y_pred_sample)\n",
    "print(\"Quick test MAE on sample data: {:.4f}\".format(mae_sample))\n",
    "\n",
    "##### Entraînement final du modèle sélectionné et prédictions sur le test\n",
    "model.fit(X_train, y_train)\n",
    "est_preds = model.predict(test_data)\n",
    "\n",
    "##### Création du fichier de soumission avec le nom du modèle utilisé\n",
    "model_name = str(model).split('(')[0]\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": sample_submission[\"id\"],\n",
    "    \"co2\": est_preds.astype(int)\n",
    "})\n",
    "submission.to_csv(f\"../result/regression/{model_name}_submission.csv\", index=False)\n",
    "print(f\"Submission saved as {model_name}_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regression-conclusion",
   "metadata": {},
   "source": [
    "## VI. Conclusion\n",
    "\n",
    "Ce défi de régression nous a permis d’explorer plusieurs techniques de modélisation. L’optimisation des hyperparamètres via HalvingRandomSearchCV a aidé à sélectionner rapidement une configuration efficace pour ExtraTreesRegressor. De plus, le système interactif permet de comparer différentes approches afin de choisir le modèle le plus adapté aux caractéristiques des données. Le fichier de soumission final est généré sous le format requis pour la compétition."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
